\section{Introduction}
Large Scale Image Classification has been a very popular task in recent years.  It's a very important task in the field of computer vision for bridging the large semantic gap between an image-just a set of pixels  and  the object it presents. Researchers have build quite a few benchmark datasets for image classification such as MNIST, Label Me etc. Researchers also developed a lot of local descriptors, Bag Of Visual Words Model(BOVW), and different classification methods such as logistic regression, support vector machine etc. 

Just in past two or three years, deep learning began to bloom for many computer vision tasks, especially for image classification. To learn about thousands of objects from millions of images, we need a model with a great capacity. Convolutional neural network(CNN) provides us such an option. By utilizing multiple layers, nonlinear transformation etc. properties, CNN can effectively learn good feature representation and achieve state-of-the-art results, especially on large scale dataset such as ImageNet Dataset which contains over 15 million labeled labeled high-resolution images belonging to roughly 22,000 categories.  

In this project, we are provided with a modified version of ImageNet Dataset. This modified dataset consists of 1,262,106 images distributed over 164 classes. Some of the classes are directly from the ImageNet dataset, while others are generated by merging multiple classes in order to make it more challenging. Each image in the dataset is represented by a vector of 900 dimensions, and is assigned to one of 164 classes. We think it may be the raw count of  clustering results of SIFT features.  1,000,000 images were randomly chosen to form the training data, and the rest images as testing data. 

In this work, we tried different methods including logistic regression(LR), support vector machine(SVM) and neural network(NN), and finally average different models' results to form the final prediction result. 